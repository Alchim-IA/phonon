# WakaScribe - Intelligence LLM et Commandes Vocales

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Ajouter le post-traitement LLM via Groq et les commandes vocales contextuelles

**Architecture:** Pipeline Whisper ‚Üí D√©tecteur commandes ‚Üí LLM Groq (optionnel) ‚Üí R√©sultat

**Tech Stack:** Rust/Tauri, Groq API (Llama 3.1 70B), keyring pour stockage s√©curis√©

---

## 1. Architecture globale

### Flux de traitement
```
Audio ‚Üí Whisper (transcription brute) ‚Üí D√©tecteur de commandes ‚Üí LLM Groq (si activ√©) ‚Üí R√©sultat final
```

### Nouveaux composants backend (Rust)
- `src-tauri/src/llm/groq_client.rs` - Client HTTP pour l'API Groq
- `src-tauri/src/llm/post_processor.rs` - Logique de post-traitement avec modes
- `src-tauri/src/llm/mod.rs` - Module LLM
- `src-tauri/src/voice_commands/parser.rs` - Parseur de commandes vocales
- `src-tauri/src/voice_commands/mod.rs` - Module commandes vocales

### Nouveaux types
```rust
#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum LlmMode {
    Off,        // Transcription brute uniquement
    Basic,      // Ponctuation + majuscules + grammaire
    Smart,      // Basic + suppression h√©sitations + reformulation
    Contextual, // Smart + adaptation au mode de dict√©e
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum DictationMode {
    General,
    Email,
    Code,
    Notes,
}
```

### Nouveaux param√®tres AppSettings
```rust
// LLM
llm_enabled: bool,              // false par d√©faut
llm_mode: LlmMode,              // Basic par d√©faut si activ√©

// Commandes vocales
voice_commands_enabled: bool,   // true par d√©faut
dictation_mode: DictationMode,  // General par d√©faut
```

Note: La cl√© API Groq est stock√©e via keyring, pas dans AppSettings.

---

## 2. Commandes vocales

### Commandes de ponctuation (d√©tection automatique)
| Voix | R√©sultat |
|------|----------|
| "point" | `.` |
| "virgule" | `,` |
| "point d'interrogation" | `?` |
| "point d'exclamation" | `!` |
| "deux points" | `:` |
| "point virgule" | `;` |
| "ouvrir parenth√®se" / "fermer parenth√®se" | `(` / `)` |
| "ouvrir guillemets" / "fermer guillemets" | `¬´` / `¬ª` |
| "√† la ligne" | `\n` |
| "nouveau paragraphe" | `\n\n` |

### Commandes d'√©dition (pr√©fixe "commande")
| Voix | Action |
|------|--------|
| "commande efface" | Supprime le dernier mot/phrase |
| "commande annuler" | Annule la derni√®re action |
| "commande tout effacer" | Vide le texte courant |
| "commande majuscules" | Met en majuscules la derni√®re phrase |
| "commande copier" | Copie dans le presse-papier |
| "commande stop" | Arr√™te l'enregistrement |

### Commandes contextuelles par mode
- **Email** : "commande signature", "commande formule politesse"
- **Code** : "commande fonction", "commande commentaire"
- **Notes** : "commande puce", "commande titre"

### D√©tection hybride
- Ponctuation : d√©tection automatique bas√©e sur le contexte (pause, position)
- Actions d'√©dition : requiert le pr√©fixe "commande"
- Le LLM en mode Smart/Contextual corrige les faux positifs √©ventuels

---

## 3. Int√©gration Groq

### Configuration API
- Endpoint : `https://api.groq.com/openai/v1/chat/completions`
- Mod√®le : `llama-3.1-70b-versatile`
- Timeout : 5 secondes
- Fallback : transcription brute si erreur/timeout

### Prompts par mode

**Mode Basic:**
```
Tu es un correcteur de texte. Corrige uniquement la ponctuation, les majuscules et les fautes de grammaire √©videntes. Ne modifie pas le sens ni le style. Retourne uniquement le texte corrig√©, sans explication.

Texte: {transcription}
```

**Mode Smart:**
```
Tu es un assistant d'√©criture. Corrige la ponctuation et la grammaire, supprime les h√©sitations (euh, hum, ben) et les r√©p√©titions inutiles. Reformule l√©g√®rement pour plus de clart√© si n√©cessaire. Retourne uniquement le texte am√©lior√©.

Texte: {transcription}
```

**Mode Contextual - Email:**
```
Tu es un assistant d'√©criture professionnelle. Transforme ce texte dict√© en email professionnel. Ajoute les formules de politesse appropri√©es si absentes. Garde un ton formel mais naturel. Retourne uniquement l'email format√©.

Texte: {transcription}
```

**Mode Contextual - Code:**
```
Tu es un assistant technique. Formate ce texte en documentation de code ou commentaire technique. Utilise la terminologie appropri√©e. Structure clairement. Retourne uniquement le texte format√©.

Texte: {transcription}
```

**Mode Contextual - Notes:**
```
Tu es un assistant de prise de notes. Organise ce texte en notes structur√©es avec puces si appropri√©. Garde les points essentiels, supprime le superflu. Retourne uniquement les notes format√©es.

Texte: {transcription}
```

### Stockage cl√© API
- Utilisation de `keyring` (d√©j√† dans le projet)
- Service : `wakascribe`
- Compte : `groq_api_key`
- Commandes Tauri : `set_groq_api_key`, `get_groq_api_key`, `validate_groq_api_key`

### Latence estim√©e
- Whisper small : ~2s
- Groq : ~200-500ms
- Total : ~2.5s (acceptable)

---

## 4. Interface utilisateur

### SettingsPanel - Nouvelle section "Intelligence (LLM)"
```
‚îå‚îÄ Intelligence (LLM) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                     ‚îÇ
‚îÇ  [Toggle] Activer le post-traitement LLM           ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  Cl√© API Groq:                                     ‚îÇ
‚îÇ  [‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢] [üëÅ] [Obtenir une cl√© ‚Üí]       ‚îÇ
‚îÇ  (lien vers https://console.groq.com/keys)         ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  Mode de correction:                               ‚îÇ
‚îÇ  ‚óã Basique - ponctuation et grammaire              ‚îÇ
‚îÇ  ‚óã Intelligent - reformulation claire              ‚îÇ
‚îÇ  ‚óã Contextuel - adapt√© au mode de dict√©e           ‚îÇ
‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### SettingsPanel - Nouvelle section "Mode de dict√©e"
```
‚îå‚îÄ Mode de dict√©e ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                     ‚îÇ
‚îÇ  [G√©n√©ral] [Email] [Code] [Notes]                  ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  [Toggle] Commandes vocales activ√©es               ‚îÇ
‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### DictationPanel - Indicateurs
- Badge "LLM" cyan quand activ√© (√† c√¥t√© du statut)
- Processing en 2 √©tapes : "Transcription..." puis "Am√©lioration..."
- LED diff√©rente pour l'√©tape LLM (cyan au lieu de magenta)

### Footer App.tsx
- Affiche le mode actif : "Whisper.cpp ¬∑ Email ¬∑ LLM" ou "Whisper.cpp ¬∑ General"

### Types TypeScript
```typescript
type LlmMode = 'off' | 'basic' | 'smart' | 'contextual';
type DictationMode = 'general' | 'email' | 'code' | 'notes';

interface AppSettings {
  // ... existants ...
  llm_enabled: boolean;
  llm_mode: LlmMode;
  voice_commands_enabled: boolean;
  dictation_mode: DictationMode;
}
```

---

## 5. Gestion des erreurs

### Erreurs Groq
| Erreur | Comportement |
|--------|--------------|
| Cl√© invalide (401) | Message d'erreur, d√©sactive LLM |
| Rate limit (429) | Fallback transcription brute, notification discr√®te |
| Timeout (>5s) | Fallback transcription brute |
| Hors-ligne | Fallback transcription brute, indicateur "offline" |

### Validation cl√© API
- Test avec requ√™te minimale √† la sauvegarde
- Affiche indicateur vert (‚úì) ou rouge (‚úó)
- Message d'erreur explicite si invalide

### Commandes vocales - Faux positifs
- Le LLM en mode Smart/Contextual corrige naturellement
- En mode Basic/Off : d√©tection contextuelle (pauses, position dans phrase)
- Possibilit√© de d√©sactiver les commandes vocales si trop de faux positifs

---

## 6. R√©sum√© des fichiers √† cr√©er/modifier

### Nouveaux fichiers
- `src-tauri/src/llm/mod.rs`
- `src-tauri/src/llm/groq_client.rs`
- `src-tauri/src/llm/post_processor.rs`
- `src-tauri/src/voice_commands/mod.rs`
- `src-tauri/src/voice_commands/parser.rs`
- `src-tauri/src/commands/llm.rs`

### Fichiers √† modifier
- `src-tauri/src/types.rs` - Nouveaux enums et champs settings
- `src-tauri/src/lib.rs` - Enregistrer nouveaux modules et commandes
- `src-tauri/src/commands/transcription.rs` - Int√©grer pipeline LLM
- `src-tauri/src/storage/config.rs` - Nouveaux champs par d√©faut
- `src-tauri/Cargo.toml` - Pas de nouvelles d√©pendances (reqwest d√©j√† pr√©sent)
- `src/types/index.ts` - Nouveaux types TypeScript
- `src/components/SettingsPanel.tsx` - Nouvelles sections UI
- `src/components/DictationPanel.tsx` - Indicateurs LLM
- `src/App.tsx` - Footer avec mode actif
